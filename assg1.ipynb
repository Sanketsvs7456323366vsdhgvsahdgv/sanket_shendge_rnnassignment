{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb8c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ff41cd-cda4-490d-9ba7-01b162d06acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Sanket\\Desktop/Job_project/Assig1 redo sutram/dataset/classification_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4381ac67-3221-4d81-aa4f-81cd86c7dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = 5000\n",
    "max_length = 20  # max words per text snippet\n",
    "oov_token = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "138d2bd9-b51a-4a26-878b-bc169c106cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c85fab-75af-49ea-8179-93c84dc04e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert texts to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296fae4a-eef2-4949-9cba-1cb96d82d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(df['label'])\n",
    "labels_categorical = to_categorical(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf9a8aa9-c128-4e4f-90cd-9ba485194c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, labels_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32abbd9-93d2-453b-8fcb-cc2de3e1d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 319\n",
      "Label mapping: {'English': 0, 'History': 1, 'Math': 2, 'Science': 3}\n",
      "Train shape: (64, 20), Test shape: (16, 20)\n"
     ]
    }
   ],
   "source": [
    "# Info for later\n",
    "print(f\"Vocabulary size: {len(tokenizer.word_index)}\")\n",
    "print(f\"Label mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04048423-66aa-4ade-8794-b08392db6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9127f3dd-754f-48d4-876d-e36c8da6784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "embedding_dim = 64\n",
    "rnn_units = 64\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0da9c777-4a78-4068-8e8c-17d2968f4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=embedding_dim),\n",
    "    SimpleRNN(rnn_units),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45759955-1eac-458a-b859-b8da444c123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f9ce02-73c6-4017-b2c0-f5f3e563c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 575ms/step - accuracy: 0.2624 - loss: 1.3768 - val_accuracy: 0.2308 - val_loss: 1.3718\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.5702 - loss: 1.2121 - val_accuracy: 0.3077 - val_loss: 1.3361\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8038 - loss: 1.0089 - val_accuracy: 0.2308 - val_loss: 1.2845\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8659 - loss: 0.7698 - val_accuracy: 0.4615 - val_loss: 1.2214\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.8597 - loss: 0.5724 - val_accuracy: 0.6154 - val_loss: 1.1609\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9697 - loss: 0.4615 - val_accuracy: 0.5385 - val_loss: 1.1533\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.9817 - loss: 0.3604 - val_accuracy: 0.5385 - val_loss: 1.1607\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.2227 - val_accuracy: 0.5385 - val_loss: 1.1808\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.1555 - val_accuracy: 0.5385 - val_loss: 1.2400\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0998 - val_accuracy: 0.6923 - val_loss: 1.2387\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d7646ac-fbc2-416a-8294-5b1f6c4c27ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5000 - loss: 1.1476\n",
      "\n",
      "✅ Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\n✅ Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf3cc3c1-9027-46c5-9e1e-01f9da2ab4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (486, 5), y shape: (486, 270)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load science corpus\n",
    "with open(\"C:/Users/Sanket/Desktop/Job_project/Assig1 redo sutram/dataset/science_corpus.txt\", \"r\") as f:\n",
    "    corpus = f.read().lower()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences([corpus])[0]\n",
    "\n",
    "# Prepare sequences of 5 words and their next word\n",
    "sequence_length = 5\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(sequence_length, len(sequences)):\n",
    "    X.append(sequences[i-sequence_length:i])  # input sequence of 5 words\n",
    "    y.append(sequences[i])  # target: next word\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode the target labels\n",
    "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Model input shape\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Save tokenizer for later use in the model\n",
    "import pickle\n",
    "with open(\"tokenizer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59ad290a-c5ea-4a29-a073-3b792e7b94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.0054 - loss: 5.5959 - val_accuracy: 0.0306 - val_loss: 5.5918\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1377 - loss: 5.5196 - val_accuracy: 0.0714 - val_loss: 5.5825\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1203 - loss: 5.4158 - val_accuracy: 0.0714 - val_loss: 5.5719\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0933 - loss: 5.1768 - val_accuracy: 0.0714 - val_loss: 5.7345\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0922 - loss: 4.9012 - val_accuracy: 0.0714 - val_loss: 6.0243\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0893 - loss: 4.7534 - val_accuracy: 0.0714 - val_loss: 5.9663\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0832 - loss: 4.7849 - val_accuracy: 0.0714 - val_loss: 5.9421\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.1072 - loss: 4.7023 - val_accuracy: 0.0714 - val_loss: 6.1322\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.1034 - loss: 4.4952 - val_accuracy: 0.0714 - val_loss: 6.3395\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.1137 - loss: 4.3648 - val_accuracy: 0.0612 - val_loss: 6.1810\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1718 - loss: 4.2530 - val_accuracy: 0.0714 - val_loss: 6.1335\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2322 - loss: 4.0820 - val_accuracy: 0.0714 - val_loss: 6.2404\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.2332 - loss: 3.8545 - val_accuracy: 0.0612 - val_loss: 6.3959\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2947 - loss: 3.7085 - val_accuracy: 0.0612 - val_loss: 6.1539\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.3877 - loss: 3.4056 - val_accuracy: 0.0612 - val_loss: 6.2233\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.3971 - loss: 3.1954 - val_accuracy: 0.0612 - val_loss: 6.3364\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.4351 - loss: 3.0077 - val_accuracy: 0.0714 - val_loss: 6.3595\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4697 - loss: 2.8741 - val_accuracy: 0.0714 - val_loss: 6.3328\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5405 - loss: 2.6437 - val_accuracy: 0.0612 - val_loss: 6.3269\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.5826 - loss: 2.4388 - val_accuracy: 0.0612 - val_loss: 6.2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 64\n",
    "rnn_units = 128\n",
    "sequence_length = 5  # Number of words in input sequence\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Size of the vocabulary (unique words)\n",
    "\n",
    "# Build the RNN model for next word prediction\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    SimpleRNN(rnn_units),\n",
    "    Dense(vocab_size, activation='softmax')  # Output layer for next word prediction\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X, y, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('next_word_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab822337-fbc6-4598-8be5-2fa8c840ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: photosynthesis is the to the which of the vibrations and as blood the the in is and and the which to in and\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model = load_model('next_word_model.h5')\n",
    "\n",
    "# Load the tokenizer (to map word indices to actual words)\n",
    "import pickle\n",
    "with open(\"tokenizer.pickle\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Function to predict the next word(s) given a seed sequence\n",
    "def predict_next_words(seed_text, next_words, model, tokenizer, sequence_length):\n",
    "    output_text = seed_text\n",
    "    for _ in range(next_words):\n",
    "        # Convert the text to sequence of integers\n",
    "        sequence = tokenizer.texts_to_sequences([output_text])[0]\n",
    "        \n",
    "        # Pad the sequence to ensure it has the correct shape\n",
    "        sequence = pad_sequences([sequence], maxlen=sequence_length, padding='pre')\n",
    "        \n",
    "        # Predict the next word\n",
    "        predicted_probabilities = model.predict(sequence, verbose=0)\n",
    "        predicted_word_index = np.argmax(predicted_probabilities)\n",
    "        \n",
    "        # Get the word corresponding to the predicted index\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index]\n",
    "        \n",
    "        # Append the predicted word to the output\n",
    "        output_text += \" \" + predicted_word\n",
    "        \n",
    "    return output_text\n",
    "\n",
    "# Example: Provide an initial seed text and generate the next 20 words\n",
    "seed_text = \"photosynthesis is the\"\n",
    "predicted_text = predict_next_words(seed_text, 20, model, tokenizer, sequence_length=5)\n",
    "print(f\"Generated Text: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488ef2f-ccd4-4a69-8494-0ae3ee58f948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
